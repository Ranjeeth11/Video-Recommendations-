{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the requried libries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://api.socialverseapp.com'\n",
    "HEADERS = {'Flic-Token': 'flic_6e2d8d25dc29a4ddd382c2383a903cf4a688d1a117f6eb43b35a1e7fadbb84b8'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_paginated_data(endpoint, params=None):\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    \n",
    "    params['resonance_algorithm'] = 'resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if'\n",
    "\n",
    "    all_data = []\n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            current_params = {**params, 'page': page, 'page_size': 1000}\n",
    "            url = f\"{BASE_URL}{endpoint}\"\n",
    "            response = requests.get(url, headers=HEADERS, params=current_params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if data.get('status') != 'success':\n",
    "                break\n",
    "\n",
    "            posts = data.get('posts', [])\n",
    "            if not posts:\n",
    "                break\n",
    "\n",
    "            all_data.extend(posts)\n",
    "\n",
    "            if len(posts) < current_params['page_size']:\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching page {page} from {endpoint}: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    return {'data': all_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    try:\n",
    "        posts = fetch_paginated_data('/posts/summary/get')\n",
    "        views = fetch_paginated_data('/posts/view')\n",
    "        likes = fetch_paginated_data('/posts/like')\n",
    "        ratings = fetch_paginated_data('/posts/rating')\n",
    "        users = fetch_paginated_data('/users/get_all')\n",
    "\n",
    "        return posts, views, likes, ratings, users\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(posts):\n",
    "    try:\n",
    "        print(\"Starting data preprocessing...\")\n",
    "\n",
    "        posts_data = pd.DataFrame(posts.get('data', []))\n",
    "        interactions = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "        if not posts_data.empty:\n",
    "            for _, post in posts_data.iterrows():\n",
    "                user_id = post.get('username')\n",
    "                post_id = post.get('id')\n",
    "                if user_id and post_id:\n",
    "                    view_weight = post.get('view_count', 0) * 1\n",
    "                    upvote_weight = post.get('upvote_count', 0) * 3\n",
    "                    rating_weight = post.get('average_rating', 0) * post.get('rating_count', 0) * 5\n",
    "\n",
    "                    total_interaction = view_weight + upvote_weight + rating_weight\n",
    "                    interactions[user_id][post_id] = total_interaction\n",
    "\n",
    "        interaction_matrix = pd.DataFrame.from_dict(interactions, orient='index').fillna(0)\n",
    "\n",
    "        features = []\n",
    "        if not posts_data.empty:\n",
    "            for _, post in posts_data.iterrows():\n",
    "                features.append({\n",
    "                    'id': post.get('id'),\n",
    "                    'category_id': post['category'][0]['id'] if isinstance(post.get('category'), list) and post['category'] else 0,\n",
    "                    'comment_count': post.get('comment_count', 0),\n",
    "                    'upvote_count': post.get('upvote_count', 0),\n",
    "                    'view_count': post.get('view_count', 0),\n",
    "                    'rating_count': post.get('rating_count', 0),\n",
    "                    'average_rating': post.get('average_rating', 0),\n",
    "                    'share_count': post.get('share_count', 0),\n",
    "                    'is_locked': 1 if post.get('is_locked') else 0,\n",
    "                    'timestamp': post.get('created_at', 0)\n",
    "                })\n",
    "\n",
    "        content_features = pd.DataFrame(features).set_index('id') if features else pd.DataFrame()\n",
    "\n",
    "        if not content_features.empty:\n",
    "            numeric_columns = content_features.select_dtypes(include=[np.number]).columns\n",
    "            content_features[numeric_columns] = (\n",
    "                content_features[numeric_columns] - content_features[numeric_columns].mean()\n",
    "            ) / content_features[numeric_columns].std()\n",
    "            content_features = content_features.fillna(0)\n",
    "\n",
    "        popularity_scores = calculate_popularity_scores(posts)\n",
    "        return interaction_matrix, content_features, popularity_scores\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing data: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate popularity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_popularity_scores(posts):\n",
    "    popularity = defaultdict(float)\n",
    "\n",
    "    if isinstance(posts, dict) and 'data' in posts:\n",
    "        current_time = datetime.now().timestamp()\n",
    "        RECENCY_WINDOW = 7 * 24 * 60 * 60\n",
    "\n",
    "        for post in posts['data']:\n",
    "            post_id = post.get('id')\n",
    "            if not post_id:\n",
    "                continue\n",
    "\n",
    "            created_at = post.get('created_at', current_time)\n",
    "            if isinstance(created_at, str):\n",
    "                try:\n",
    "                    created_at = pd.to_datetime(created_at).timestamp()\n",
    "                except:\n",
    "                    created_at = current_time\n",
    "\n",
    "            time_diff = current_time - created_at\n",
    "            recency_factor = max(0, 1 - (time_diff / RECENCY_WINDOW))\n",
    "\n",
    "            engagement = (\n",
    "                post.get('view_count', 0) * 1 +\n",
    "                post.get('upvote_count', 0) * 3 +\n",
    "                post.get('rating_count', 0) * post.get('average_rating', 0) * 0.05 +\n",
    "                post.get('share_count', 0) * 4\n",
    "            )\n",
    "\n",
    "            popularity[post_id] = engagement * recency_factor\n",
    "\n",
    "        if popularity:\n",
    "            max_score = max(popularity.values())\n",
    "            if max_score > 0:\n",
    "                popularity = {k: v / max_score for k, v in popularity.items()}\n",
    "\n",
    "    return popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, interaction_matrix, content_features, popularity_scores, n_recommendations=10):\n",
    "    try:\n",
    "        if interaction_matrix.empty or user_id not in interaction_matrix.index:\n",
    "            return get_popular_recommendations(popularity_scores, n_recommendations)\n",
    "        else:\n",
    "            return get_personalized_recommendations(user_id, interaction_matrix, content_features, popularity_scores, n_recommendations)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recommendations: {str(e)}\")\n",
    "        return get_popular_recommendations(popularity_scores, n_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popular recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular_recommendations(popularity_scores, n_recommendations):\n",
    "    return sorted(popularity_scores.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personalized recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personalized_recommendations(user_id, interaction_matrix, content_features, popularity_scores, n_recommendations):\n",
    "    user_interactions = interaction_matrix.loc[user_id]\n",
    "    uninteracted_posts = [post_id for post_id in popularity_scores.keys() if post_id not in user_interactions or user_interactions[post_id] == 0]\n",
    "\n",
    "    recommendations = []\n",
    "    for post_id in uninteracted_posts:\n",
    "        score = popularity_scores[post_id]\n",
    "        if not content_features.empty and post_id in content_features.index:\n",
    "            similar_posts = get_similar_posts(post_id, content_features)\n",
    "            for similar_post_id, similarity in similar_posts:\n",
    "                if similar_post_id in user_interactions:\n",
    "                    score += similarity * user_interactions[similar_post_id]\n",
    "\n",
    "        recommendations.append((post_id, score))\n",
    "\n",
    "    return sorted(recommendations, key=lambda x: x[1], reverse=True)[:n_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get similar posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_posts(post_id, content_features):\n",
    "    if post_id not in content_features.index:\n",
    "        return []\n",
    "\n",
    "    post_features = content_features.loc[post_id].values.reshape(1, -1)\n",
    "    similarities = cosine_similarity(post_features, content_features.values)[0]\n",
    "\n",
    "    similar_posts = sorted([(pid, sim) for pid, sim in zip(content_features.index, similarities) if pid != post_id], key=lambda x: x[1], reverse=True)\n",
    "    return similar_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save recommendations to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recommendations_to_csv(user_id, recommendations, posts, filename=None):\n",
    "    try:\n",
    "        post_map = {post.get('id'): post for post in posts.get('data', [])}\n",
    "        enriched_recommendations = [\n",
    "            {\n",
    "                'id': post_id,\n",
    "                'name': post_map.get(post_id, {}).get('title', 'Unknown Title'),\n",
    "                'link': post_map.get(post_id, {}).get('link', ''),\n",
    "                'score': score\n",
    "            }\n",
    "            for post_id, score in recommendations\n",
    "        ]\n",
    "\n",
    "        recommendations_df = pd.DataFrame(enriched_recommendations)\n",
    "        recommendations_df['user_id'] = user_id\n",
    "        recommendations_df['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        if filename is None:\n",
    "            filename = f\"recommendations_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "        os.makedirs('recommendations', exist_ok=True)\n",
    "        filepath = os.path.join('recommendations', filename)\n",
    "        recommendations_df.to_csv(filepath, index=False)\n",
    "\n",
    "        print(f\"Recommendations saved to {filepath}\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving recommendations to CSV: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "Recommendations saved to recommendations\\recommendations_kinha_20241212_032908.csv\n",
      "    id                      name  link          score user_id  \\\n",
      "0   19      WE ARE MADE OF STARS   NaN  147912.448795   kinha   \n",
      "1   31               Don't laugh   NaN  145898.205835   kinha   \n",
      "2   44         escape the matrix   NaN  142970.798560   kinha   \n",
      "3   38              meditateðŸ§˜â€â™‚ï¸   NaN  139709.978549   kinha   \n",
      "4   59   push through the pain ðŸ«¡   NaN  138551.356533   kinha   \n",
      "5   43         why are you here?   NaN  134350.861654   kinha   \n",
      "6   33          Enough is enough   NaN  133811.645844   kinha   \n",
      "7  633  The Perspective Limiter.   NaN  133241.484843   kinha   \n",
      "8   40     trials to test you...   NaN  131774.222755   kinha   \n",
      "9   52             Matthew 25:29   NaN  131515.618389   kinha   \n",
      "\n",
      "             timestamp  \n",
      "0  2024-12-12 03:29:08  \n",
      "1  2024-12-12 03:29:08  \n",
      "2  2024-12-12 03:29:08  \n",
      "3  2024-12-12 03:29:08  \n",
      "4  2024-12-12 03:29:08  \n",
      "5  2024-12-12 03:29:08  \n",
      "6  2024-12-12 03:29:08  \n",
      "7  2024-12-12 03:29:08  \n",
      "8  2024-12-12 03:29:08  \n",
      "9  2024-12-12 03:29:08  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        posts, views, likes, ratings, users = fetch_data()\n",
    "        interaction_matrix, content_features, popularity_scores = preprocess_data(posts)\n",
    "\n",
    "        user_id = \"kinha\"\n",
    "        recommendations = get_recommendations(user_id, interaction_matrix, content_features, popularity_scores)\n",
    "\n",
    "        filepath = save_recommendations_to_csv(user_id, recommendations, posts)\n",
    "        if filepath:\n",
    "            print(pd.read_csv(filepath))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "MAE: 0.1750\n",
      "RMSE: 0.1803\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate_recommendations(interaction_matrix, recommendations, test_data):\n",
    "\n",
    "    try:\n",
    "        # Flatten recommendations into a DataFrame\n",
    "        predicted_scores = []\n",
    "        actual_scores = []\n",
    "        \n",
    "        for user_id, user_recommendations in recommendations.items():\n",
    "            for post_id, predicted_score in user_recommendations:\n",
    "                # Find actual interaction score in the test data\n",
    "                actual_score = test_data.get((user_id, post_id), 0)  # Default to 0 if not in test set\n",
    "                if actual_score > 0:  # Only evaluate where actual score exists\n",
    "                    predicted_scores.append(predicted_score)\n",
    "                    actual_scores.append(actual_score)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        mae = mean_absolute_error(actual_scores, predicted_scores)\n",
    "        rmse = np.sqrt(mean_squared_error(actual_scores, predicted_scores))\n",
    "        \n",
    "        return {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulated interaction matrix (ground truth)\n",
    "    interaction_matrix = pd.DataFrame([\n",
    "        {\"user_id\": \"u1\", \"post_id\": \"p1\", \"actual_score\": 5},\n",
    "        {\"user_id\": \"u1\", \"post_id\": \"p2\", \"actual_score\": 3},\n",
    "        {\"user_id\": \"u2\", \"post_id\": \"p3\", \"actual_score\": 4},\n",
    "        {\"user_id\": \"u3\", \"post_id\": \"p1\", \"actual_score\": 1}\n",
    "    ])\n",
    "    \n",
    "    # Simulated recommendations\n",
    "    recommendations = {\n",
    "        \"u1\": [(\"p1\", 4.8), (\"p2\", 3.2)],\n",
    "        \"u2\": [(\"p3\", 3.9)],\n",
    "        \"u3\": [(\"p1\", 1.2)]\n",
    "    }\n",
    "    \n",
    "    # Ground truth test data (user-post interaction scores)\n",
    "    test_data = {\n",
    "        (\"u1\", \"p1\"): 5,\n",
    "        (\"u1\", \"p2\"): 3,\n",
    "        (\"u2\", \"p3\"): 4,\n",
    "        (\"u3\", \"p1\"): 1\n",
    "    }\n",
    "    \n",
    "    metrics = evaluate_recommendations(interaction_matrix, recommendations, test_data)\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(f\"MAE: {metrics['MAE']:.4f}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
